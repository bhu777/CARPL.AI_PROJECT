# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kbrj4xtG8RZzSmwTpXpbyqJfohTwTrI0
"""

#take input of an image

#filter as per different colours of vibgyor

#from different images obtained , main content will be in white only

#get only major contours information from all of these images

#get text written in all these images

#take input of an image

!sudo apt install tesseract-ocr
!pip install pytesseract

import cv2
import numpy as np
from imutils.perspective import four_point_transform
import cv2
import numpy
import pytesseract

#filter as per different colours of vibgyor

#get major contour information only

def major_contour_boundary_found(threshed_image):
  
  # Finding Contours
  # Use a copy of the image e.g. edged.copy()
  # since findContours alters the image
  contours, hierarchy = cv2.findContours(threshed_image,
  	cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
  total_length_of_countours_found=[]
  major_contours_found=[]
  x=0
  sum=0
  
  #to remove outliers
  try:
    for i in range(len(contours)):
      sum+=len(contours[i])
  
    average_length_of_contours=int(sum/len(contours))
    for i in range(len(contours)):
      if (len(contours[i]) > average_length_of_contours):
        major_contours_found.append(contours[i])
    # print("Number of Contours found = " + str(len(major_contours_found)))
    return major_contours_found
  except:
    return False

def labels_found(threshed_image):
  ret3, thresh = cv2.threshold(threshed_image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
  edgeImg_8u = np.asarray(thresh, np.uint8)
  text=pytesseract.image_to_string(thresh)
  return text

def totalInfo(contours,labels,count_c,count_l):    
  contours_found_from_image={}
  labels_extracted_from_image={} 
  if(contours):
    for i in range(len(contours)):
      value='''contour_coordinates_{}'''.format(count_c)
      contours_found_from_image[value]=contours[i]
      count_c+=1
  
  if(labels):
    for i in labels.split('\n'):
      value='''label_{}'''.format(count_l)
      labels_extracted_from_image[value]=i
      count_l+=1
  return contours_found_from_image, labels_extracted_from_image , count_c, count_l

def findInfoInImage(image_path):
  img = cv2.imread(image_path)
  count_c=0
  count_l=0
  
  ORANGE_MIN = np.array([5, 50, 50],np.uint8)
  ORANGE_MAX = np.array([15, 255, 255],np.uint8)
  
  hsv_img = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)
  
  frame_threshed_orange = cv2.inRange(hsv_img, ORANGE_MIN, ORANGE_MAX)
  
  contour_in_orange=major_contour_boundary_found(frame_threshed_orange)
  labels_in_orange=labels_found(frame_threshed_orange)
  
  orange_contour , orange_labels, count_c, count_l = totalInfo(contour_in_orange,labels_in_orange,count_c, count_l)
  
  
  #red mask
  img_hsv=cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
  
  # lower mask (0-10)
  RED_MIN = np.array([0,50,50])
  RED_MAX = np.array([10,255,255])
  mask0 = cv2.inRange(img_hsv, RED_MIN, RED_MAX)
  
  # upper mask (170-180)
  RED_MIN = np.array([170,50,50])
  RED_MAX = np.array([180,255,255])
  mask1 = cv2.inRange(img_hsv, RED_MIN, RED_MAX)
  
  # join my masks
  frame_threshed_red = mask0+mask1
  
  contour_in_red=major_contour_boundary_found(frame_threshed_red)
  labels_in_red=labels_found(frame_threshed_red)
  
  red_contour , red_labels, count_c, count_l = totalInfo(contour_in_red,labels_in_red,count_c, count_l)
  
  
  #yellow mask
  
  YELLOW_MIN = np.array([22, 93, 0],np.uint8)
  YELLOW_MAX = np.array([45, 255, 255],np.uint8)
  
  hsv_img = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)
  
  frame_threshed_yellow = cv2.inRange(hsv_img, YELLOW_MIN, YELLOW_MAX)
  
  contour_in_yellow=major_contour_boundary_found(frame_threshed_yellow)
  labels_in_yellow=labels_found(frame_threshed_yellow)
  
  yellow_contour , yellow_labels, count_c, count_l = totalInfo(contour_in_yellow,labels_in_yellow,count_c, count_l)
  
  #blue mask
  
  BLUE_MIN = np.array([200,0,0],np.uint8)
  BLUE_MAX = np.array([250,250,255],np.uint8)
  hsv_img = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)
  
  frame_threshed_blue = cv2.inRange(hsv_img, BLUE_MIN, BLUE_MAX)
  
  contour_in_blue=major_contour_boundary_found(frame_threshed_blue)
  labels_in_blue=labels_found(frame_threshed_blue)
  
  blue_contour , blue_labels, count_c, count_l = totalInfo(contour_in_blue,labels_in_blue,count_c, count_l)
  
  
  #green mask
  
  GREEN_MIN = np.array([40,40,40],np.uint8)
  GREEN_MAX = np.array([70,255,255],np.uint8)
  hsv_img = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)
  
  frame_threshed_green = cv2.inRange(hsv_img, GREEN_MIN, GREEN_MAX)
  
  contour_in_green=major_contour_boundary_found(frame_threshed_green)
  labels_in_green=labels_found(frame_threshed_green)
  
  green_contour , green_labels, count_c, count_l = totalInfo(contour_in_green,labels_in_green,count_c, count_l)
  
  #merging all the dictionaries
  contour_coordinates= {**orange_contour,**red_contour,**yellow_contour,**green_contour,**blue_contour}
  labels_info= {**orange_labels,**red_labels,**yellow_labels,**green_labels,**blue_labels}
  
  return contour_coordinates, labels_info

if __name__ == "__main__":
    image_path='/usr/app/src/img.jpg'
    contours , labels = findInfoInImage(image_path)
    print(contours)
    print(labels)

